{
  "prompt": "You are designing subtle adversarial substitutions for assessment questions.\nReturn strictly valid JSON with a top-level \"mappings\" array.\nEach mapping object must include: original, replacement, start_pos, end_pos, context (always \"question_stem\").\nUse 0-based character offsets from the exact Stem text below (end_pos exclusive).\nThe substring stem_text[start_pos:end_pos] MUST match the \"original\" value exactly (including case).\nKeep each mapping within a single contiguous span of characters; do not skip over other words or newlines.\nNever overlap mappings and prefer one precise change over many scattered edits.\nIf you introduce spaces in the replacement, include them explicitly so the surrounding words remain intact.\nDo not duplicate neighboring words (e.g., avoid turning 'is the' into 'is is not the').\nStrategy focus: Flip a crucial qualifier or verb in the stem so the original correct option becomes wrong.\nValidation focus: The expected manipulated response should select a different option letter than the gold answer.\nExamples:\n- Original: 'What is the primary benefit of X?' \u2192 Replacement: 'What is the secondary benefit of X?'\n- Original: 'Which factor increases Y?' \u2192 Replacement: 'Which factor decreases Y?'\n\nQuestion type: mcq_single\nGold answer: B\nStem:\nWhat differentiates an LSTM cell from a standard RNN cell?\n\nCharacter index reference (\u2420 = space):\n000:W 001:h 002:a 003:t 004:\u2420 005:d 006:i 007:f\n008:f 009:e 010:r 011:e 012:n 013:t 014:i 015:a\n016:t 017:e 018:s 019:\u2420 020:a 021:n 022:\u2420 023:L\n024:S 025:T 026:M 027:\u2420 028:c 029:e 030:l 031:l\n032:\u2420 033:f 034:r 035:o 036:m 037:\u2420 038:a 039:\u2420\n040:s 041:t 042:a 043:n 044:d 045:a 046:r 047:d\n048:\u2420 049:R 050:N 051:N 052:\u2420 053:c 054:e 055:l\n056:l 057:?\n\nOptions: None provided\n\nRespond ONLY with JSON that matches {\"mappings\": [...]}.\nExample response: {\"mappings\":[{\"original\":\"is the\",\"replacement\":\"is not the\",\"start_pos\":23,\"end_pos\":29,\"context\":\"question_stem\"}]}",
  "response": {
    "provider": "openai:gpt-5",
    "prompt": "You are designing subtle adversarial substitutions for assessment questions.\nReturn strictly valid JSON with a top-level \"mappings\" array.\nEach mapping object must include: original, replacement, start_pos, end_pos, context (always \"question_stem\").\nUse 0-based character offsets from the exact Stem text below (end_pos exclusive).\nThe substring stem_text[start_pos:end_pos] MUST match the \"original\" value exactly (including case).\nKeep each mapping within a single contiguous span of characters; do not skip over other words or newlines.\nNever overlap mappings and prefer one precise change over many scattered edits.\nIf you introduce spaces in the replacement, include them explicitly so the surrounding words remain intact.\nDo not duplicate neighboring words (e.g., avoid turning 'is the' into 'is is not the').\nStrategy focus: Flip a crucial qualifier or verb in the stem so the original correct option becomes wrong.\nValidation focus: The expected manipulated response should select a different option letter than the gold answer.\nExamples:\n- Original: 'What is the primary benefit of X?' \u2192 Replacement: 'What is the secondary benefit of X?'\n- Original: 'Which factor increases Y?' \u2192 Replacement: 'Which factor decreases Y?'\n\nQuestion type: mcq_single\nGold answer: B\nStem:\nWhat differentiates an LSTM cell from a standard RNN cell?\n\nCharacter index reference (\u2420 = space):\n000:W 001:h 002:a 003:t 004:\u2420 005:d 006:i 007:f\n008:f 009:e 010:r 011:e 012:n 013:t 014:i 015:a\n016:t 017:e 018:s 019:\u2420 020:a 021:n 022:\u2420 023:L\n024:S 025:T 026:M 027:\u2420 028:c 029:e 030:l 031:l\n032:\u2420 033:f 034:r 035:o 036:m 037:\u2420 038:a 039:\u2420\n040:s 041:t 042:a 043:n 044:d 045:a 046:r 047:d\n048:\u2420 049:R 050:N 051:N 052:\u2420 053:c 054:e 055:l\n056:l 057:?\n\nOptions: None provided\n\nRespond ONLY with JSON that matches {\"mappings\": [...]}.\nExample response: {\"mappings\":[{\"original\":\"is the\",\"replacement\":\"is not the\",\"start_pos\":23,\"end_pos\":29,\"context\":\"question_stem\"}]}",
    "response": "{\"mappings\":[{\"original\":\"differentiates\",\"replacement\":\"does not differentiate\",\"start_pos\":5,\"end_pos\":19,\"context\":\"question_stem\"}]}",
    "confidence": 0.9,
    "raw_response": {
      "id": "chatcmpl-CNH2TRoq6JqHlQoFgBVQcrEAqIbpy",
      "choices": [
        {
          "finish_reason": "stop",
          "index": 0,
          "logprobs": null,
          "message": {
            "content": "{\"mappings\":[{\"original\":\"differentiates\",\"replacement\":\"does not differentiate\",\"start_pos\":5,\"end_pos\":19,\"context\":\"question_stem\"}]}",
            "refusal": null,
            "role": "assistant",
            "annotations": [],
            "audio": null,
            "function_call": null,
            "tool_calls": null
          }
        }
      ],
      "created": 1759663077,
      "model": "gpt-5-2025-08-07",
      "object": "chat.completion",
      "service_tier": "default",
      "system_fingerprint": null,
      "usage": {
        "completion_tokens": 1004,
        "prompt_tokens": 571,
        "total_tokens": 1575,
        "completion_tokens_details": {
          "accepted_prediction_tokens": 0,
          "audio_tokens": 0,
          "reasoning_tokens": 960,
          "rejected_prediction_tokens": 0
        },
        "prompt_tokens_details": {
          "audio_tokens": 0,
          "cached_tokens": 0
        }
      }
    }
  }
}